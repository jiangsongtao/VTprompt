# VTprompt

This repository contains the code for the paper: "Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models".
[pipeline4.pdf](https://github.com/jiangsongtao/VTprompt/files/14892212/pipeline4.pdf)

## Installation

### Environment Setup
Please follow the instructions in [Grounded Segment Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) to set up the environment.

## Usage

1. Building Vprompt
2. Using Tprompt to prompt Multimodal Large Language Models for generating answers.
